{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter optimisation\n",
    "\n",
    "In this notebook I'll use Bayesian Optimisation in order to tune hyperparameters. This technique is way better than grid search and random search. It uses different algorithms, I'm going to explore the TPE (Tree Parzen Estimators) algorithm implemented by hyperopt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing utils \n",
    "os.chdir('C:\\\\Users\\\\hugo_\\\\OneDrive\\\\Documentos\\\\DataScience\\\\Repos\\\\kaggle_credit_risk\\\\code')\n",
    "\n",
    "from utils import *\n",
    "\n",
    "# Data directory\n",
    "os.chdir('C:\\\\Users\\\\hugo_\\\\OneDrive\\\\Documentos\\\\DataScience\\\\Repos\\\\kaggle_credit_risk\\\\data\\\\treated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train_eng.csv')\n",
    "test = pd.read_csv('test_eng.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our validation metric\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Importing lgbm and xgboost\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID_train = train.SK_ID_CURR.values\n",
    "ID_test = test.SK_ID_CURR.values\n",
    "\n",
    "y_train = train.TARGET.values\n",
    "\n",
    "X_train = train.drop(['SK_ID_CURR', 'TARGET'], axis=1).values\n",
    "X_test = test.drop(['SK_ID_CURR'], axis=1).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining search space\n",
    "First, let us define our search space for LGBM. The hyperparameters must be defined as some sort of propabilistic distribution. They are the priors that serves as input to our bayesian optimization algorithm. The hyperopt library offers some default distributions, such as uniform, log uniform and others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the search space\n",
    "from hyperopt import hp\n",
    "\n",
    "space_lgbm = {\n",
    "    'class_weight': hp.choice('class_weight', [None, 'balanced']),\n",
    "    'boosting_type': hp.choice('boosting_type', [{'boosting_type': 'gbdt', 'subsample': hp.uniform('gdbt_subsample', 0.5, 1)}, \n",
    "                                                 {'boosting_type': 'dart', 'subsample': hp.uniform('dart_subsample', 0.5, 1)},\n",
    "                                                 {'boosting_type': 'goss', 'subsample': 1.0}]),\n",
    "    'num_leaves': hp.quniform('num_leaves', 30, 150, 1),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.2)),\n",
    "    'subsample_for_bin': hp.quniform('subsample_for_bin', 20000, 300000, 20000),\n",
    "    'min_child_samples': hp.quniform('min_child_samples', 20, 500, 5),\n",
    "    'reg_alpha': hp.uniform('reg_alpha', 0.0, 1.0),\n",
    "    'reg_lambda': hp.uniform('reg_lambda', 0.0, 1.0),\n",
    "    'colsample_bytree': hp.uniform('colsample_by_tree', 0.6, 1.0)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After defining our search space, in which the Tree Parzen Estimators algorithm is going to make some assumptions about the probabilistic surface it will optimize, let's create a file to follow up the results of the optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import tpe, Trials, STATUS_OK, fmin, space_eval\n",
    "import csv\n",
    "\n",
    "# optimization algorithm\n",
    "tpe_algorithm = tpe.suggest\n",
    "\n",
    "# Keep track of results\n",
    "bayes_trials = Trials()\n",
    "\n",
    "# Getting a fraction of data to optimise parameters (low ram, sorry :T)\n",
    "indexes = np.random.randint(0, X_train.shape[0], 200000) # 200000 rows\n",
    "X_train_ = X_train[indexes,:]\n",
    "y_train_ = y_train[indexes]\n",
    "\n",
    "# create the lgbm Dataset\n",
    "train_set = lgb.Dataset(X_train_, label = y_train_)\n",
    "\n",
    "# Output file\n",
    "out_file = 'gbm_trials.csv'\n",
    "of_connection = open(out_file, 'w')\n",
    "writer = csv.writer(of_connection)\n",
    "\n",
    "# Write the headers to the file\n",
    "writer.writerow(['loss', 'params', 'iteration', 'estimators', 'train_time'])\n",
    "of_connection.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Than, in order to our algorithm to work, it is necessary to create a function it will optimize. I'll be writing specifically for LGBM, but later in this notebook I'll write a more generic function that supports other algorithms. \n",
    "\n",
    "This function must return at least 2 parameters: the loss, which is the objective to optimize, and a flag called STATUS_OK, which serves as a go on flag. The other parameters returned are optional, but is interesting to keep track of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer\n",
    "\n",
    "N_FOLDS = 5\n",
    "\n",
    "def objective_lgbm(params, n_folds = N_FOLDS):\n",
    "    \"\"\"Objective function for Gradient Boosting Machine Hyperparameter Optimization\"\"\"\n",
    "    \n",
    "    # Keep track of evals\n",
    "    global ITERATION\n",
    "    \n",
    "    ITERATION += 1\n",
    "    \n",
    "    # Retrieve the subsample if present otherwise set to 1.0\n",
    "    subsample = params['boosting_type'].get('subsample', 1.0)\n",
    "    \n",
    "    # Extract the boosting type\n",
    "    params['boosting_type'] = params['boosting_type']['boosting_type']\n",
    "    params['subsample'] = subsample\n",
    "    \n",
    "    # Make sure parameters that need to be integers are integers\n",
    "    for parameter_name in ['num_leaves', 'subsample_for_bin', 'min_child_samples']:\n",
    "        params[parameter_name] = int(params[parameter_name])\n",
    "    \n",
    "    start = timer()\n",
    "    \n",
    "    # Perform n_folds cross validation\n",
    "    cv_results = lgb.cv(params, train_set, num_boost_round = 10000, nfold = n_folds, \n",
    "                        early_stopping_rounds = 100, metrics = 'auc', seed = 50)\n",
    "    \n",
    "    run_time = timer() - start\n",
    "    \n",
    "     # Extract the best score\n",
    "    best_score = np.max(cv_results['auc-mean'])\n",
    "    \n",
    "    # Loss must be minimized\n",
    "    loss = 1 - best_score\n",
    "    \n",
    "    # Boosting rounds that returned the highest cv score\n",
    "    n_estimators = int(np.argmax(cv_results['auc-mean']) + 1)\n",
    "\n",
    "    # Write to the csv file ('a' means append)\n",
    "    of_connection = open(out_file, 'a')\n",
    "    writer = csv.writer(of_connection)\n",
    "    writer.writerow([loss, params, ITERATION, n_estimators, run_time])\n",
    "    \n",
    "    # Dictionary with information for evaluation\n",
    "    return {'loss': loss, 'params': params, 'iteration': ITERATION,\n",
    "            'estimators': n_estimators, \n",
    "            'train_time': run_time, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After all set up, let's call the fmin function, which will call the objective_lgbm and the search space it will covers to optimize.\n",
    "\n",
    "This algorithms works as follows:\n",
    "- Build a surrogate probability model of the objective function\n",
    "- Find the hyperparameters that perform best on the surrogate\n",
    "- Apply these hyperparameters to the true objective function\n",
    "- Update the surrogate model incorporating the new results\n",
    "- Repeat steps 2â€“4 until max iterations or time is reached\n",
    "\n",
    "If you want to dig deeper into this process, read the [excelent article](https://towardsdatascience.com/a-conceptual-explanation-of-bayesian-model-based-hyperparameter-optimization-for-machine-learning-b8172278050f) on the subject and the [original paper](https://app.sigopt.com/static/pdf/SigOpt_Bayesian_Optimization_Primer.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/98 [01:14<1:59:51, 74.14s/it, best loss: 0.23829185473987946]"
     ]
    }
   ],
   "source": [
    "# Global variable\n",
    "global  ITERATION\n",
    "\n",
    "ITERATION = 0\n",
    "MAX_EVALS = 100\n",
    "\n",
    "# Run optimization\n",
    "best = fmin(fn = objective_lgbm, space = space_lgbm, algo = tpe.suggest, \n",
    "            max_evals = MAX_EVALS, trials = bayes_trials, rstate = np.random.RandomState(50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(space_eval(space_lgbm, best))\n",
    "\n",
    "# Or it could be done by using the trials object\n",
    "\n",
    "# Sort the trials with lowest loss (highest AUC) first\n",
    "bayes_trials_results = sorted(bayes_trials.results, key = lambda x: x['loss'])\n",
    "print(bayes_trials_results[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.read_csv('gbm_trials.csv')\n",
    "\n",
    "# Sort with best scores on top and reset index for slicing\n",
    "results.sort_values('loss', ascending = True, inplace = True)\n",
    "results.reset_index(inplace = True, drop = True)\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When the results are saved into a csv file, it gets converted into a string. Let's use the ast function to convert it back.\n",
    "import ast\n",
    "\n",
    "# Convert from a string to a dictionary\n",
    "ast.literal_eval(results.loc[0, 'params'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating best results\n",
    "\n",
    "Now it's time to evaluate out results. Hope to get good AUC with this tunned model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the ideal number of estimators and hyperparameters\n",
    "best_bayes_estimators = int(results.loc[0, 'estimators'])\n",
    "best_bayes_params = ast.literal_eval(results.loc[0, 'params']).copy()\n",
    "\n",
    "# Re-create the best model and train on the training data\n",
    "best_bayes_model = lgb.LGBMClassifier(n_estimators = best_bayes_estimators, n_jobs = -1, \n",
    "                                       objective = 'binary', random_state = 50, **best_bayes_params)\n",
    "best_bayes_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating submission file\n",
    "\n",
    "pd.DataFrame(\n",
    "    {\n",
    "        'SK_ID_CURR': ID_test,\n",
    "        'TARGET': best_bayes_model.predict_proba(X_test)[:,1]\n",
    "    }\n",
    ").to_csv('submission_lgbm_tunned.csv', index = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generic Bayesian Optimisation Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(space):\n",
    "    \"\"\"Objective function for Generic Model Hyperparameter Optimization\"\"\"\n",
    "    \n",
    "    # Keep track of evals\n",
    "    global ITERATION\n",
    "    \n",
    "    ITERATION += 1\n",
    "        \n",
    "    # KFold cross-validation\n",
    "    kf = StratifiedKFold(n_splits = 5)\n",
    "    \n",
    "    # Getting the model\n",
    "    model = space['model'](**space['params'])\n",
    "\n",
    "    # Starting\n",
    "    start = timer()\n",
    "    \n",
    "    # Perform n_folds cross validation\n",
    "    roc_aucs = []\n",
    "    for train_index, val_index in kf.split(X_train[:1000,:], y_train[:1000]):\n",
    "        X_train_, y_train_ = X_train[train_index, :], y_train[train_index]\n",
    "        X_val_, y_val_ = X_train[val_index, :], y_train[val_index]\n",
    "\n",
    "        # Change the model here\n",
    "        model.fit(X_train_, y_train_)\n",
    "        roc_aucs.append(roc_auc_score(y_val_, model.predict_proba(X_val_)[:,1]))\n",
    "    \n",
    "    run_time = timer() - start\n",
    "    \n",
    "     # Extract the best score\n",
    "    best_score = np.mean(roc_aucs)\n",
    "    \n",
    "    # Loss must be minimized\n",
    "    loss = 1 - best_score\n",
    "\n",
    "    # Write to the csv file ('a' means append)\n",
    "    of_connection = open(out_file, 'a')\n",
    "    writer = csv.writer(of_connection)\n",
    "    writer.writerow([loss, space, ITERATION, run_time])\n",
    "    \n",
    "    # Dictionary with information for evaluation\n",
    "    return {'loss': loss, 'params': space, 'iteration': ITERATION,\n",
    "            'train_time': run_time, 'status': STATUS_OK}\n",
    "\n",
    "def optimize(objective, space, trials, MAX_EVALS = 120, output_file = 'BayesOpt.csv', random_state = 42):\n",
    "    \n",
    "    # Output file\n",
    "    out_file = output_file\n",
    "    of_connection = open(out_file, 'w')\n",
    "    writer = csv.writer(of_connection)\n",
    "\n",
    "    # Write the headers to the file\n",
    "    writer.writerow(['loss', 'params', 'iteration', 'train_time'])\n",
    "    of_connection.close()\n",
    "    \n",
    "    # Global variable\n",
    "    global  ITERATION\n",
    "\n",
    "    ITERATION = 0\n",
    "\n",
    "    # Run optimization\n",
    "    best = fmin(fn = objective, space = space, algo = tpe.suggest, \n",
    "                max_evals = MAX_EVALS, trials = trials, rstate = np.random.RandomState(42))\n",
    "    \n",
    "    return space_eval(space, best)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
